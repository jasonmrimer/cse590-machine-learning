{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 4\n",
    "For this problem, you need to use the built-in sklearn digits dataset. You can load this data using Sklearn.datasets.load_digits (*, n_class=10,return_X_y=False, as_frame=False) Divide the data into training and test sets using train_test_split and random_state=0 The goal is to train a Random Forest classifier and optimize its performance on this data.\n",
    "1. Identify the most important parameters that affect the performance of the Random Forest classifier and outline your experimental design (using 4-fold cross validation) to learn the optimal values for these parameters.\n",
    "2. Analyze the results of the classifier using its optimal parameters and comment on its generalization capability.\n",
    "3. Visualize and explain the relevant features identified by the Random Forest classifier.\n",
    "+ Create a white 8x8 image that represents the original 64 features. Map each identified relevant feature to this 2D image and display it using a grey scale that reflects its importance (e.g. 0 most relevant feature and 255  least relevant feature).\n",
    "4. Identify one misclassified sample from each class (if they exist). Visualize each misclassified sample as an 8x8 image, and use its nearest neighbors and the learned important features to explain why it was misclassified.\n",
    "\n",
    "Hint: for examples on how to read this data and visualize it, check\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glrauto-examples-classification-plot-digits-classification-py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import and setup data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import sklearn_evaluation\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "digits = sklearn.datasets.load_digits(n_class=10, return_X_y=False, as_frame=False)\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data,\n",
    "    digits.target,\n",
    "    random_state=0\n",
    ")\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Random Forest classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### General methods for training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def grid_search_random_forest(\n",
    "        n_estimators,\n",
    "        max_features,\n",
    "        max_depth=None,\n",
    "        max_leaf_nodes=None\n",
    "):\n",
    "    parameters = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "    }\n",
    "    include_additional_parameters(max_depth, max_leaf_nodes, parameters)\n",
    "\n",
    "    classifier = RandomForestClassifier(random_state=0)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        classifier,\n",
    "        parameters,\n",
    "        cv=4,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print_grid_search_results(grid_search, parameters)\n",
    "    return grid_search\n",
    "\n",
    "\n",
    "def print_grid_search_results(grid_search, parameters):\n",
    "    for parameter in parameters:\n",
    "        print(f'Best {parameter}:', grid_search.best_params_[parameter])\n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "\n",
    "def include_additional_parameters(max_depth, max_leaf_nodes, parameters):\n",
    "    if max_depth is not None:\n",
    "        parameters.update({'max_depth': max_depth})\n",
    "    if max_leaf_nodes is not None:\n",
    "        parameters.update({'max_leaf_nodes': max_leaf_nodes})\n",
    "\n",
    "\n",
    "def graph_grid_search_random_forest(grid_search):\n",
    "    print(grid_search.cv_results_)\n",
    "    sklearn_evaluation.evaluator.plot.grid_search(\n",
    "        grid_search.cv_results_,\n",
    "        change=(\"n_estimators\", \"max_features\")\n",
    "    )\n",
    "\n",
    "    plt.title(\"Random Forest\")\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"max_features\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_3d_heatmap(grid_results):\n",
    "    result_params = grid_results.cv_results_['params']\n",
    "    df = pd.DataFrame(result_params)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x = df.loc[:, 'n_estimators']\n",
    "    y = df.loc[:, 'max_features']\n",
    "    z = df.loc[:, 'max_depth']\n",
    "    c = grid_results.cv_results_['mean_test_score']\n",
    "    img = ax.scatter(x, y, z, c=c, cmap=plt.hot())\n",
    "    fig.colorbar(img)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Start finding optimal parameters\n",
    "use 4-fold cross validation and heatmaps to determine best params. keep track of times in case coomputing resources in jeopardy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trial 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_estimators = np.linspace(20, 40, 3, dtype=int)\n",
    "max_features = np.linspace(1, 12, 6, dtype=int)\n",
    "\n",
    "grid_search = % time grid_search_random_forest( n_estimators, max_features )\n",
    "graph_grid_search_random_forest(grid_search)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trial 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_estimators = np.linspace(40, 100, 3, dtype=int)\n",
    "max_features = np.linspace(7, 16, 6, dtype=int)\n",
    "\n",
    "grid_search_t2 = %time grid_search_random_forest( n_estimators, max_features )\n",
    "graph_grid_search_random_forest(grid_search_t2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trial 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_estimators = np.linspace(100, 140, 5, dtype=int)\n",
    "max_features = np.linspace(5, 9, 5, dtype=int)\n",
    "\n",
    "grid_search_t3 = %time grid_search_random_forest( n_estimators, max_features )\n",
    "graph_grid_search_random_forest(grid_search_t3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trial 4 with Pruning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_estimators = np.linspace(50, 90, 5, dtype=int)\n",
    "max_features = np.linspace(10, 14, 5, dtype=int)\n",
    "max_depth = np.linspace(5, 50, 5, dtype=int)\n",
    "\n",
    "grid_search = % time grid_search_random_forest(n_estimators, max_features, max_depth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trial 5 more pruning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_estimators = np.linspace(90, 130, 5, dtype=int)\n",
    "max_features = np.linspace(6, 10, 5, dtype=int)\n",
    "max_depth = np.linspace(5, 50, 5, dtype=int)\n",
    "\n",
    "grid_search_t5_pruning = grid_search_random_forest(n_estimators, max_features, max_depth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_3d_heatmap(grid_search_t5_pruning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_estimators = np.linspace(60, 100, 3, dtype=int)\n",
    "max_features = np.linspace(9, 15, 6, dtype=int)\n",
    "max_depth = np.linspace(5, 50, 5, dtype=int)\n",
    "\n",
    "grid_search = % time grid_search_random_forest(n_estimators, max_features, max_depth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_estimators = np.linspace(60, 100, 3, dtype=int)\n",
    "max_features = np.linspace(9, 15, 3, dtype=int)\n",
    "max_depth = np.linspace(10, 30, 3, dtype=int)\n",
    "max_leaf_nodes = np.linspace(1, 50, 5, dtype=int)\n",
    "\n",
    "grid_search = % time grid_search_random_forest(n_estimators, max_features, max_depth, max_leaf_nodes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_estimators = np.linspace(60, 100, 3, dtype=int)\n",
    "max_features = np.linspace(12, 18, 3, dtype=int)\n",
    "max_depth = np.linspace(5, 15, 3, dtype=int)\n",
    "max_leaf_nodes = np.linspace(40, 140, 5, dtype=int)\n",
    "\n",
    "grid_search = %time grid_search_random_forest(n_estimators, max_features, max_depth, max_leaf_nodes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the trained model\n",
    "use the optimal hyperparameters to set on a final random forest to use throughout the subsequent modeling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=120,\n",
    "    max_features=8,\n",
    "    max_depth=16,\n",
    "    oob_score=True\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_predictions = rf.predict(X_test)\n",
    "print(\"Train: \", rf.score(X_train, y_train))\n",
    "print(\"Test: \", rf.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Train: \", dt.score(X_train, y_train))\n",
    "print(\"Test: \", dt.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "# ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "plot the feature importance\n",
    "Plot the forest feature importances via mean decrease in impurity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(4)\n",
    "plt.bar([x for x in range(len(importances))], importances)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "collect most important feature and sum their importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "count_over_threshold = sum(map(lambda x: x >= 0.03, importances))\n",
    "most_important = heapq.nlargest(count_over_threshold, importances)\n",
    "least_important = heapq.nsmallest(45, importances)\n",
    "\n",
    "indices_of_most_important_features = []\n",
    "for item in most_important:\n",
    "    correct_actual_item_index = np.argwhere(importances == item)\n",
    "    indices_of_most_important_features.append(correct_actual_item_index[0][0])\n",
    "\n",
    "print(indices_of_most_important_features)\n",
    "print(f'Most important count: {len(most_important)}')\n",
    "print(f'Most important sum: {len(most_important)}')\n",
    "print('Least 45 sum:', sum(least_important))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix\n",
    "test the viability of the model, accuracy etc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_predictions)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze Misclassified"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "general functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def map_importance_mask_over_digit_image(\n",
    "        item_to_display_1d,\n",
    "        mask_over_item_1d,\n",
    "        expected_result,\n",
    "        actual_result\n",
    "):\n",
    "    importance_mask = mask_over_item_1d.reshape(8, 8)\n",
    "    display_item_in_8x8(plt, item_to_display_1d, expected_result, actual_result)\n",
    "\n",
    "    display_mask_over_image(importance_mask)\n",
    "\n",
    "\n",
    "def display_mask_over_image(importance_mask):\n",
    "    plt.imshow(\n",
    "        importance_mask,\n",
    "        cmap=plt.cm.gray_r,\n",
    "        interpolation='none',\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        aspect='equal',\n",
    "        alpha=0\n",
    "    )\n",
    "\n",
    "    def rect(pos):\n",
    "        r = plt.Rectangle(pos - 0.5, 1, 1, facecolor=\"none\", edgecolor=\"cyan\", linewidth=2)\n",
    "        plt.gca().add_patch(r)\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(importance_mask.shape[1]), np.arange(importance_mask.shape[0]))\n",
    "    m = np.c_[x[importance_mask.astype(bool)], y[importance_mask.astype(bool)]]\n",
    "    for pos in m:\n",
    "        rect(pos)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_item_in_8x8(plt, item_to_display_1d, expected_result, actual_result):\n",
    "    misclassified_image = item_to_display_1d.reshape(8, 8)\n",
    "    _, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "    axes.set_axis_off()\n",
    "    axes.imshow(\n",
    "        misclassified_image,\n",
    "        cmap=plt.cm.gray_r,\n",
    "        interpolation=\"nearest\",\n",
    "    )\n",
    "    ax.set_title(f\"Expected: {expected_result}\\nActual: {actual_result}\")\n",
    "\n",
    "def map_misclassification_analysis(\n",
    "        correct_expected_item_index,\n",
    "        misclassifed_item_index,\n",
    "        correct_actual_item_index,\n",
    "):\n",
    "    map_importance_mask_over_digit_image(\n",
    "        X_train[correct_expected_item_index],\n",
    "        importance_mask_1d,\n",
    "        y_train[correct_expected_item_index],\n",
    "        y_train[correct_expected_item_index]\n",
    "    )\n",
    "\n",
    "    map_importance_mask_over_digit_image(\n",
    "        X_test[misclassifed_item_index],\n",
    "        importance_mask_1d,\n",
    "        y_test[misclassifed_item_index],\n",
    "        y_predictions[misclassifed_item_index]\n",
    "    )\n",
    "\n",
    "    map_importance_mask_over_digit_image(\n",
    "        X_train[correct_actual_item_index],\n",
    "        importance_mask_1d,\n",
    "        y_train[correct_actual_item_index],\n",
    "        y_train[correct_actual_item_index]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "misclassified_indices = np.where((y_predictions != y_test))\n",
    "print(misclassified_indices)\n",
    "\n",
    "\n",
    "def generate_most_important_mask():\n",
    "    global importance_image, i, importance_mask_1d\n",
    "    importance_image = []\n",
    "    for i in range(0, 64):\n",
    "        importance_image.append(0)\n",
    "        if indices_of_most_important_features.__contains__(i):\n",
    "            importance_image[i] = 1\n",
    "    return np.array(importance_image)\n",
    "\n",
    "importance_mask_1d = generate_most_important_mask()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices_of_correct_8 = np.where((y_predictions == y_test) & (y_predictions == 8))\n",
    "print(indices_of_correct_8)\n",
    "\n",
    "indices_of_correct_1 = np.where((y_predictions == y_test) & (y_predictions == 1))\n",
    "print(indices_of_correct_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "print('Train: ', knn.score(X_train, y_train))\n",
    "print('Test: ', knn.score(X_test, y_test))\n",
    "\n",
    "# knn_predictions = knn.predict(X_test, y_test)\n",
    "\n",
    "distances, neighbor_indices = knn.kneighbors(X_test[misclassified_indices[0]])\n",
    "\n",
    "print(neighbor_indices)\n",
    "# print(misclassified_indices[0])\n",
    "v_misclass = np.vstack(misclassified_indices[0])\n",
    "print(v_misclass)\n",
    "# neighbor_indices = np.array(neighbor_indices)\n",
    "# print(neighbor_indices)\n",
    "# misclass = np.array(misclassified_indices[0])\n",
    "# print(misclass)\n",
    "neighbor_map = np.concatenate((v_misclass, neighbor_indices), 1)\n",
    "neighbor_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices_of_misclassified_by_number = np.where(\n",
    "    (y_predictions != y_test) & (y_test == 9)\n",
    ")\n",
    "print(indices_of_misclassified_by_number)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "show the most important features heatmap and the feature mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "no_mask = np.array(np.zeros(64))\n",
    "map_importance_mask_over_digit_image(\n",
    "    importances,\n",
    "    no_mask,\n",
    "    '0-9',\n",
    "    '0-9'\n",
    ")\n",
    "\n",
    "map_importance_mask_over_digit_image(\n",
    "    importances,\n",
    "    importance_mask_1d,\n",
    "    '0-9',\n",
    "    '0-9'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices = neighbor_indices\n",
    "\n",
    "print(y_test[misclassified_indices[0]])\n",
    "columns = [\"Misclassified Test idx\", \"True Class\", \"Pred Class\"]\n",
    "for i in range(3):\n",
    "    columns += [\"Neigbor#{}_idx\".format(i + 1), \"Neigbor#{}_True Class\".format(i + 1),\n",
    "        \"Neigbor#{}_Distance\".format(i + 1)]\n",
    "\n",
    "print(columns)\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "df[\"Misclassified Test idx\"] = misclassified_indices[0]\n",
    "df[\"True Class\"] = y_test[misclassified_indices[0]]\n",
    "df[\"Pred Class\"] = y_predictions[misclassified_indices[0]]\n",
    "for i in range(3):\n",
    "    df[\"Neigbor#{}_idx\".format(i + 1)] = indices[:, i]\n",
    "    df[\"Neigbor#{}_True Class\".format(i + 1)] = y_train[indices[:, i]]\n",
    "    df[\"Neigbor#{}_Distance\".format(i + 1)] = np.around(distances[:, i], decimals=2)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (expect_true_neighbor, actual_false, actual_neighbor)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analyze Class 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (expect_true_neighbor, actual_false, actual_neighbor)\n",
    "indices_of_correct_number = np.where(y_train == 0)\n",
    "print(indices_of_correct_number)\n",
    "\n",
    "map_misclassification_analysis(1051, 117, 18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analyze Class 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices_of_correct_number = np.where(y_train == 3)\n",
    "print(indices_of_correct_number)\n",
    "\n",
    "map_misclassification_analysis(120, 378, 36)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices_of_correct_number = np.where(y_train == 4)\n",
    "print(indices_of_correct_number)\n",
    "\n",
    "map_misclassification_analysis(41, 315, 418)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices_of_correct_number = np.where(y_train == 5)\n",
    "print(indices_of_correct_number)\n",
    "\n",
    "map_misclassification_analysis(12, 56, 1145)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices_of_correct_number = np.where(y_train == 1)\n",
    "print(indices_of_correct_number)\n",
    "\n",
    "map_misclassification_analysis(1192, 124, 25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices_of_correct_number = np.where(y_train == 5)\n",
    "print(indices_of_correct_number)\n",
    "\n",
    "map_misclassification_analysis(1275, 130, 12)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}